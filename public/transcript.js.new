let recognition = null;
let mediaRecorder = null;
let audioChunks = [];
let isRecording = false;
let startTime = null;

async function setupRecording() {
    if (!window.SpeechRecognition && !window.webkitSpeechRecognition) {
        alert('Speech recognition not supported in this browser.');
        return false;
    }

    try {
        recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        
        mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
        };
        
        setupEventListeners();
        return true;
    } catch (error) {
        console.error('Setup error:', error);
        alert('Error setting up recording. Please check microphone permissions.');
        return false;
    }
}

function setupEventListeners() {
    recognition.onstart = () => {
        console.log('Recognition started');
        document.getElementById('status').textContent = 'Recording...';
        startTime = Date.now();
    };

    recognition.onerror = (event) => {
        console.error('Recognition error:', event.error);
        if (event.error === 'not-allowed') {
            stopRecording();
            alert('Microphone access denied.');
        }
    };

    recognition.onend = () => {
        if (isRecording) {
            recognition.start();
        }
    };

    recognition.onresult = (event) => {
        for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript;
            if (event.results[i].isFinal) {
                addTranscriptLine(transcript);
            }
        }
    };
}

function getTimestamp() {
    if (!startTime) return '0:00';
    const elapsed = Math.floor((Date.now() - startTime) / 1000);
    const minutes = Math.floor(elapsed / 60);
    const seconds = elapsed % 60;
    return `${minutes}:${seconds.toString().padStart(2, '0')}`;
}

function addTranscriptLine(text) {
    const transcriptArea = document.querySelector('.transcript-area');
    if (transcriptArea) {
        const timestamp = document.createElement('div');
        timestamp.className = 'timestamp';
        timestamp.textContent = getTimestamp();
        
        const textDiv = document.createElement('div');
        textDiv.className = 'text';
        textDiv.textContent = text;
        
        transcriptArea.appendChild(timestamp);
        transcriptArea.appendChild(textDiv);
        transcriptArea.scrollTop = transcriptArea.scrollHeight;
    }
}

async function toggleRecording() {
    if (!recognition) {
        if (!await setupRecording()) return;
    }

    isRecording = !isRecording;
    const button = document.querySelector('.record-button');

    if (isRecording) {
        recognition.start();
        mediaRecorder.start();
        audioChunks = [];
        startTime = Date.now();
    } else {
        recognition.stop();
        mediaRecorder.stop();
        
        mediaRecorder.onstop = () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            const audioUrl = URL.createObjectURL(audioBlob);
            const link = document.createElement('a');
            link.href = audioUrl;
            link.download = `recording-${new Date().toISOString()}.wav`;
            link.click();
            URL.revokeObjectURL(audioUrl);
        };
    }
}

document.addEventListener('DOMContentLoaded', () => {
    const recordButton = document.querySelector('.record-button');
    recordButton.addEventListener('click', toggleRecording);
});
